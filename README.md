<h2> Mobility ML Papers </h2>



<ul>

                             

 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(1).pdf" style="text-decoration:none;">Attend and Attack: Attention Guided Adversarial Attacks on Visual Question Answering Models</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(2).pdf" style="text-decoration:none;">Multimodal Medical Image Retrieval based on Latent Topic Modeling</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(3).pdf" style="text-decoration:none;">Unifying and Merging Well-trained Deep Neural Networks for Inference Stage</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(4).pdf" style="text-decoration:none;">Semi-Supervised Multimodal Deep Learning for RGB-D Object Recognition</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(5).pdf" style="text-decoration:none;">Microsoft COCO: Common Objects in Context</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(6).pdf" style="text-decoration:none;">Deep Fragment Embeddings for Bidirectional Image Sentence Mapping</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(7).pdf" style="text-decoration:none;">Show and Tell: A Neural Image Caption Generator</a></li>

 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(8).pdf" style="text-decoration:none;"> Deep Visual-Semantic Alignments for Generating Image Descriptions </a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(9).pdf" style="text-decoration:none;">A Dataset for Movie Description</a></li>
  
   
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(10).pdf" style="text-decoration:none;">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(11).pdf" style="text-decoration:none;">What's Cookin'? Interpreting Cooking Videos using Text, Speech and Vision</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(12).pdf" style="text-decoration:none;">VQA: Visual Question Answering</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(13).pdf" style="text-decoration:none;">Building a Large-scale Multimodal Knowledge Base System for Answering Visual Queries</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(14).pdf" style="text-decoration:none;">Multimodal Deep Learning for Robust RGB-D Object Recognition</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(15).pdf" style="text-decoration:none;">Order-Embeddings of Images and Language</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(16).pdf" style="text-decoration:none;">VisualWord2Vec (vis-w2v): Learning Visually Grounded Word Embeddings Using Abstract Scenes</a></li>

  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(17).pdf" style="text-decoration:none;">MovieQA: Understanding Stories in Movies through Question-Answering</a></li>   
  
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(18).pdf" style="text-decoration:none;">Hollywood in Homes: Crowdsourcing Data
Collection for Activity Understanding</a></li> 

  
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(19).pdf" style="text-decoration:none;">Generative Adversarial Text to Image Synthesis</a></li> 

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(20).pdf" style="text-decoration:none;">Learning to Communicate with
Deep Multi-Agent Reinforcement Learning</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(21).pdf" style="text-decoration:none;">Review Networks for Caption Generation</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(22).pdf" style="text-decoration:none;">Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings</a></li> 
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(23).pdf" style="text-decoration:none;">Towards Transparent AI Systems:
Interpreting Visual Question Answering Models</a></li> 
 

   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(24).pdf" style="text-decoration:none;">Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(25).pdf" style="text-decoration:none;">SoundNet: Learning Sound
Representations from Unlabeled Video</a></li>                              
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(26).pdf" style="text-decoration:none;">Visual Dialog</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(27).pdf" style="text-decoration:none;">Multi-Agent Cooperation and the Emergence of (Natural) Language</a></li>
   
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(28).pdf" style="text-decoration:none;">Deep Voice: Real-time Neural Text-to-Speech</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(29).pdf" style="text-decoration:none;">Zero-Shot Learning - The Good, the Bad and the Ugly </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(30).pdf" style="text-decoration:none;">Emergence of Grounded Compositional Language in Multi-Agent Populations</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(31).pdf" style="text-decoration:none;">Learning Robust Visual-Semantic Embeddings</a></li> 
    <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(32).pdf" style="text-decoration:none;">Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning</a></li> 

   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(33).pdf" style="text-decoration:none;">Towards Building Large Scale Multimodal Domain-Aware Conversation Systems</a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(34).pdf" style="text-decoration:none;">Generating Descriptions with Grounded and Co-Referenced People</a></li> 
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(35).pdf" style="text-decoration:none;">Deep Multimodal Representation Learning from Temporal Data</a></li> 

  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(36).pdf" style="text-decoration:none;">Learning to Reason: End-to-End Module Networks for Visual Question Answering</a></li> 
 
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(37).pdf" style="text-decoration:none;">End-to-End Multimodal Emotion Recognition using Deep Neural Networks</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(38).pdf" style="text-decoration:none;">Deep Voice 2: Multi-Speaker Neural Text-to-Speech</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(39).pdf" style="text-decoration:none;">Gated-Attention Architectures for Task-Oriented Language Grounding</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(40).pdf" style="text-decoration:none;">Natural Language Does Not Emerge 'Naturally' in Multi-Agent Dialog</a></li>                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(41).pdf" style="text-decoration:none;">SCAN: Learning Hierarchical Compositional Visual Concepts</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(42).pdf" style="text-decoration:none;">Tensor Fusion Network for Multimodal Sentiment Analysis</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(43).pdf" style="text-decoration:none;">Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering</a></li>
 <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(44).pdf" style="text-decoration:none;">Localizing Moments in Video with Natural Language</a></li>
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(45).pdf" style="text-decoration:none;">Answering Visual-Relational Queries in Web-Extracted Knowledge Graphs</a></li>  
   
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(46).pdf" style="text-decoration:none;">Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data</a></li> 
                             
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(47).pdf" style="text-decoration:none;">Fooling Vision and Language Models
Despite Localization and Attention Mechanism</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(48).pdf" style="text-decoration:none;">Emergent Translation in Multi-Agent Communication</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(49).pdf" style="text-decoration:none;">Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning</a></li>
                              
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(50).pdf" style="text-decoration:none;">Multimodal Probabilistic Model-Based Planning for Human-Robot Interaction</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(51).pdf" style="text-decoration:none;">Learning Multi-ModalWord Representation Grounded in Visual Context</a></li>
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(52).pdf" style="text-decoration:none;">Look, Imagine and Match:
Improving Textual-Visual Cross-Modal Retrieval with Generative Models</a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(53).pdf" style="text-decoration:none;">Neural Motifs: Scene Graph Parsing with Global Context</a></li>
 
<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(54).pdf" style="text-decoration:none;">Vision-and-Language Navigation: Interpreting visually-grounded navigation instructions in real environments </a></li>

<li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(55).pdf" style="text-decoration:none;">Video Captioning via Hierarchical Reinforcement Learning</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(56).pdf" style="text-decoration:none;">Embodied Question Answering </a></li>                              

  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(57).pdf" style="text-decoration:none;">Don't Just Assume; Look and Answer:
Overcoming Priors for Visual Question Answering</a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(58).pdf" style="text-decoration:none;">Grounding Referring Expressions in Images by Variational Context</a></li>
    <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(59).pdf" style="text-decoration:none;">Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning</a></li>
 
  <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(60).pdf" style="text-decoration:none;">Semi-supervised Multimodal Hashing </a></li>
 
   <li><a target="_blank" href="https://github.com/manjunath5496/Mobility-ML-Papers/blob/master/mo(61).pdf" style="text-decoration:none;"> Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions</a></li>
 </ul>
